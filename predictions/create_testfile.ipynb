{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import dissertation.tools.utils as utils\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import glob\n",
    "import scipy.signal as signal\n",
    "import os\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from skimage.transform import resize\n",
    "from speech2ult.tools.tal_io import read_ultrasound_tuple\n",
    "from speech2ult.tools.transform_ultrasound import transform_ultrasound\n",
    "from speech2ult.tools.voice_activity_detection import detect_voice_activity, separate_silence_and_speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resize_ult(ult, n_scan, n_echo):\n",
    "    \"\"\"\n",
    "    resize the ult to new size n_scan x n_echo. adapted from ultrasuite tools core.py\n",
    "    :return: ult\n",
    "    \"\"\"\n",
    "\n",
    "    resized = []\n",
    "    for i, image in enumerate(ult):\n",
    "        temp = resize(image, output_shape=(n_scan, n_echo), order=0, mode='reflect', clip=False,\n",
    "                      preserve_range=True, anti_aliasing=False)\n",
    "        temp = temp.round().astype(int)\n",
    "        resized.append(temp)\n",
    "\n",
    "    ult = np.array(resized)\n",
    "    return ult\n",
    "\n",
    "def load_ult(file):\n",
    "    \"\"\"load, downsample and resize ultrasound, returned with the sync offset in seconds\"\"\"\n",
    "    ult, param_file = read_ultrasound_tuple(file, shape='3d', cast=None, truncate=None)\n",
    "    offset = param_file['TimeInSecsOfFirstFrame']\n",
    "    # current n_frames * target_fps/current_fps\n",
    "    target_frames = int(ult.shape[0] * 60 / param_file['FramesPerSec'])\n",
    "    ult = utils.resize(ult, target_frames)\n",
    "    # resize dimensions\n",
    "    ult = resize_ult(ult, 64, 128)\n",
    "\n",
    "\n",
    "    return ult, offset\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"Clean the dlc pandas dataset and return np array of features\"\"\"\n",
    "    body_parts = data.loc['bodyparts'].values + '_' + data.loc['coords'].values\n",
    "    data.columns = body_parts\n",
    "    data.drop(index=['bodyparts', 'coords'], inplace=True)\n",
    "    del_col = [col for col in data.columns if col.endswith('likelihood')]\n",
    "    data.drop(columns=del_col, inplace=True)\n",
    "    # get rid of columns for hyoid, mandible and short tendon as well\n",
    "    if 'hyoid_x' in data.columns:\n",
    "        del_parts = ['hyoid_x', 'hyoid_y','mandible_x', 'mandible_y', 'shortTendon_x', 'shortTendon_y']\n",
    "        data.drop(columns=del_parts, inplace=True)\n",
    "\n",
    "    return data.values\n",
    "\n",
    "def apply_butter(dlc_feats):\n",
    "    \"\"\"apply butterworth filter to each column (body part)\"\"\"\n",
    "    filtered = np.empty_like(dlc_feats)\n",
    "    fc = 10  # Cut-off frequency of the filter\n",
    "    w = fc / (60 / 2)  # Normalize the frequency\n",
    "    b, a = signal.butter(5, w, 'low')\n",
    "\n",
    "    for col in range(dlc_feats.shape[1]):\n",
    "        filtered[:, col] = signal.filtfilt(b, a, dlc_feats[:, col])\n",
    "\n",
    "    return filtered\n",
    "\n",
    "def apply_medfilt(dlc_feats):\n",
    "    \"\"\"apply median filter to each column (body part)\"\"\"\n",
    "    filtered = np.empty_like(dlc_feats)\n",
    "    for col in range(dlc_feats.shape[1]):\n",
    "        filtered[:, col] = signal.medfilt(dlc_feats[:, col], 7)\n",
    "\n",
    "    return filtered\n",
    "\n",
    "def load_dlc_ult(basename, path, butter=False, med=False):\n",
    "    \"\"\"\n",
    "    read in dlc ult. takes optional filter args\n",
    "    \"\"\"\n",
    "    csv_file = glob.glob(os.path.join(path, f'day2_{basename}_ult*.csv'))[0]\n",
    "    data = pd.read_csv(csv_file, index_col=0)\n",
    "    ult_features = clean_data(data).astype(float)\n",
    "\n",
    "    # apply smoothing filters to dlc\n",
    "    if butter:\n",
    "        ult_features = apply_butter(ult_features)\n",
    "    if med:\n",
    "        ult_features = apply_medfilt(ult_features)\n",
    "\n",
    "    return ult_features\n",
    "\n",
    "def apply_sync(ult, ult_fps, wav, wav_sr, dlc):\n",
    "    \"\"\"all should be aligned at begining, need to trim the ends and return\"\"\"\n",
    "\n",
    "    ult_dur = ult.shape[0] / ult_fps\n",
    "    wav_dur = wav.shape[0] / wav_sr\n",
    "    dlc_dur = dlc.shape[0] / ult_fps\n",
    "\n",
    "    min_sec = np.min((ult_dur, wav_dur, dlc_dur))\n",
    "    ult_end = int(round(ult_fps * min_sec))\n",
    "    wav_end = int(round(wav_sr * min_sec))\n",
    "\n",
    "    return ult[:ult_end], wav[:wav_end], dlc[:ult_end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TestFile:\n",
    "    def __init__(self, basename, ult, wav, sr, dlc_ult):\n",
    "        self.basename = basename\n",
    "        self.ult = ult\n",
    "        self.wav = wav\n",
    "        self.sr = sr\n",
    "        self.dlc = dlc_ult\n",
    "        self.aud_scalar = None\n",
    "        self.ult_scalar = None\n",
    "        self.dlc_scalar = None\n",
    "        self.aud_feat = None\n",
    "        self.window = None\n",
    "        self.lstm = None\n",
    "        self.get_butter()\n",
    "        self.get_med()\n",
    "        self.get_bothfilt()\n",
    "\n",
    "    def get_butter(self):\n",
    "        \"\"\"apply butterworth filter to each column (body part)\"\"\"\n",
    "        filtered = np.empty_like(self.dlc)\n",
    "        fc = 10  # Cut-off frequency of the filter\n",
    "        w = fc / (60 / 2)  # Normalize the frequency\n",
    "        b, a = signal.butter(5, w, 'low')\n",
    "\n",
    "        for col in range(self.dlc.shape[1]):\n",
    "            filtered[:, col] = signal.filtfilt(b, a, self.dlc[:, col])\n",
    "\n",
    "        self.butter = filtered\n",
    "\n",
    "    def get_med(self):\n",
    "        \"\"\"apply median filter to each column (body part)\"\"\"\n",
    "        filtered = np.empty_like(self.dlc)\n",
    "        for col in range(self.dlc.shape[1]):\n",
    "            filtered[:, col] = signal.medfilt(self.dlc[:, col], 7)\n",
    "\n",
    "        self.medfilt = filtered\n",
    "\n",
    "    def get_bothfilt(self):\n",
    "        \"\"\"apply median filter to each column (body part)\"\"\"\n",
    "        filtered = np.empty_like(self.dlc)\n",
    "        for col in range(self.dlc.shape[1]):\n",
    "            filtered[:, col] = signal.medfilt(self.butter[:, col], 7)\n",
    "\n",
    "        self.bothfilt = filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# choose path to file dir and choose files to open\n",
    "path = 'speech2ult/predictions/test_data'\n",
    "files = ['088_aud', '133_aud', '226_aud']\n",
    "# change the file to create testfile for and run from here\n",
    "# for file in files:\n",
    "file = files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482, 64, 128) (345, 22)\n"
     ]
    }
   ],
   "source": [
    "# load in the data - ult, wav and dlc_ult\n",
    "true_ult, offset = load_ult(os.path.join(path, file))\n",
    "wav, sr = librosa.load(os.path.join(path, file + '.wav'), offset=offset, sr=20000)\n",
    "true_dlc = load_dlc_ult(file, path)\n",
    "\n",
    "print(true_ult.shape, true_dlc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345, 64, 128) (345, 22)\n"
     ]
    }
   ],
   "source": [
    "# sync\n",
    "true_ult, wav, true_dlc = apply_sync(true_ult, 60, wav, sr, true_dlc)\n",
    "print(true_ult.shape, true_dlc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 088_aud VAD 1.44 - 4.05 -> in frames 86:243\n",
    "# 133_aud VAD 1.53 - 5.04 -> 91:303\n",
    "# 226_aud VAD 1.44 - 2.73 -> 86:164\n",
    "# want to keep pad with 12 frames 0.2s\n",
    "# get time segments\n",
    "# time_segments = detect_voice_activity(wav,sr)\n",
    "# print(time_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# apply VAD by hand with padding of 0.2s which is 12 frames\n",
    "if file == '088_aud':\n",
    "    s, e = 74, 255\n",
    "    s1, e1 = int((1.44-0.2) * sr), int((4.05+0.2) * sr)\n",
    "elif file == '133_aud':\n",
    "    s, e = 79, 314\n",
    "    s1, e1 = int((1.53-0.2) * sr), int((5.04+0.2) * sr)\n",
    "elif file == '226_aud':\n",
    "    s, e = 74, 176\n",
    "    s1, e1 = int((1.44-0.2) * sr), int((2.73+0.2) * sr)\n",
    "\n",
    "true_ult, wav, true_dlc = true_ult[s:e], wav[s1:e1], true_dlc[s:e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.91 3.9166666666666665\n"
     ]
    }
   ],
   "source": [
    "# check duration\n",
    "print(wav.shape[0] / sr, true_ult.shape[0] / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testfile = TestFile(file, true_ult, wav, sr, true_dlc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get audio features\n",
    "def get_aud_feats(wav, deltas=True):\n",
    "    \"\"\"get the audio features from a loaded wav, return as (frames, features)\"\"\"\n",
    "    feats = librosa.feature.mfcc(\n",
    "        y=wav,\n",
    "        sr=sr,\n",
    "        n_mfcc=20,\n",
    "        hop_length= int(sr*(1/60)),\n",
    "        n_fft=int(sr*0.02)\n",
    "    )\n",
    "    if deltas:\n",
    "        deltas = librosa.feature.delta(feats)\n",
    "        feats = np.concatenate((feats,deltas))\n",
    "    return feats.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 40) (235, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "aud_feat = get_aud_feats(wav)\n",
    "print(aud_feat.shape, true_ult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we actually only need to normalize aud features - load in scalars from dict\n",
    "dlc_dict = 'speech2ult/predictions/test_data/PARAM_DICTS_ffn_dlc_2022-08-03.pickle'\n",
    "window_dict='speech2ult/predictions/test_data/PARAM_DICTS_ffn_w_2022-08-03.pickle'\n",
    "with open(dlc_dict, 'rb') as file:\n",
    "    dlc_params, aud_params = pickle.load(file)\n",
    "with open(window_dict, 'rb') as file:\n",
    "    ult_params, _ = pickle.load(file)\n",
    "\n",
    "# get scalars and check size\n",
    "aud_feat = aud_params['scalar'].transform(aud_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testfile.aud_feat = aud_feat\n",
    "testfile.aud_scalar = aud_params['scalar']\n",
    "testfile.ult_scalar = ult_params['scalar']\n",
    "testfile.dlc_scalar = dlc_params['scalar']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# format for window - keep number of frames same to true ult\n",
    "def apply_window(aud_in):\n",
    "    # get dims of aud_in\n",
    "    frames, n_feats = aud_in.shape\n",
    "\n",
    "    # create new aud array with space for window\n",
    "    aud_out = np.empty((frames, 5, n_feats))\n",
    "\n",
    "    # populate new arrays\n",
    "    for i in range(2, frames-3):  # i the first frame in the window\n",
    "        aud_out[i] = aud_in[i-2:i+3]\n",
    "\n",
    "    # need to populate the edges 0, 1, -1, -2\n",
    "    first = aud_in[0]\n",
    "    last = aud_in[-1]\n",
    "    aud_out[0,0], aud_out[0,1], aud_out[0, 2:] = first, first, aud_in[0:3]\n",
    "    aud_out[1,0], aud_out[1, 1:] = first, aud_in[:4]\n",
    "    aud_out[-1,:3], aud_out[-1, 3], aud_out[-1, 4]  = aud_in[-3:], last, last\n",
    "    aud_out[-2,:4], aud_out[-2, 4]  = aud_in[-4:], last\n",
    "\n",
    "    return aud_out.reshape((frames, 5 * n_feats))\n",
    "testfile.window = apply_window(testfile.aud_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# format for lstm - keep number of frames same to true ult\n",
    "def apply_lb(aud_in, lb):\n",
    "    # get dims of aud_in\n",
    "    frames, n_feats = aud_in.shape\n",
    "    if n_feats == 40:\n",
    "        n_feats = 20\n",
    "        aud_in = aud_in[:, :20]\n",
    "\n",
    "    # create new aud array with space for lb\n",
    "    aud_out = np.empty((frames, lb, n_feats))\n",
    "\n",
    "    # populate new arrays\n",
    "    for i in range(lb-1, frames):\n",
    "        aud_out[i] = aud_in[i-lb+1:i+1]\n",
    "\n",
    "    # need to populate the edges 0-8\n",
    "    for i in range(lb-1):\n",
    "        aud_out[i, :lb-1-i] = np.tile(aud_in[0], (lb-1-i, 1)) # padding\n",
    "        aud_out[i, lb-1-i:] = aud_in[0:i+1]\n",
    "\n",
    "    return aud_out\n",
    "\n",
    "testfile.lstm = apply_lb(testfile.aud_feat, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pickle testfile\n",
    "pick_path = os.path.join('/Users/jacobrosen/Desktop/Edinburgh/Dissertation/project_code/predictions/test_data', f'{testfile.basename}_testfile.pickle')\n",
    "with open(pick_path, 'wb') as file:\n",
    "    pickle.dump(testfile, file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
